import{_ as e,c as r,o as t,a}from"./app.89d965e1.js";const l="/blog/assets/circle.78d31463.svg",_=JSON.parse('{"title":"尾声","description":"","frontmatter":{},"headers":[{"level":2,"title":"1. 性能指标 ⏱","slug":"_1-性能指标-⏱","link":"#_1-性能指标-⏱","children":[]},{"level":2,"title":"2. 持续优化 📈","slug":"_2-持续优化-📈","link":"#_2-持续优化-📈","children":[]},{"level":2,"title":"3. 监控与测试 💻","slug":"_3-监控与测试-💻","link":"#_3-监控与测试-💻","children":[]},{"level":2,"title":"4. 自动化 🛠","slug":"_4-自动化-🛠","link":"#_4-自动化-🛠","children":[]},{"level":2,"title":"参考资料","slug":"参考资料","link":"#参考资料","children":[]}],"relativePath":"performance/END.md"}'),o={name:"performance/END.md"},i=a('<h1 id="尾声" tabindex="-1">尾声 <a class="header-anchor" href="#尾声" aria-hidden="true">#</a></h1><p>我们这次的「前端性能优化之旅」已经到了尾声，还记得我们这次旅程的初衷么 —— 从整个前端访问链条的角度，来理解与掌握前端性能优化的知识和技术。</p><p>最后，再和大家聊一聊性能优化实践相关的话题。</p><h2 id="_1-性能指标-⏱" tabindex="-1">1. 性能指标 ⏱ <a class="header-anchor" href="#_1-性能指标-⏱" aria-hidden="true">#</a></h2><p>Web 发展到现今阶段，性能指标已经不再只是 <code>DOMContentLoad</code> 和 <code>load</code> 这样的“面向浏览器”的指标，更多的会是以用户为中心（user-centric）的指标，例如：</p><ul><li>FP (First Paint)</li><li>FID (First Input Delay)</li><li>FCP (First Contentful Paint)</li><li>FMP (First Meaningful Paint)</li><li>TTI (Time to interactive)</li><li>……</li></ul><p>所以在性能优化之前最重要的还是明确你的监控指标和分析维度，关于性能指标其实也是一个可以继续聊下去的内容，这里就不展开了，以后有机会希望把这部分也补充进来。</p><h2 id="_2-持续优化-📈" tabindex="-1">2. 持续优化 📈 <a class="header-anchor" href="#_2-持续优化-📈" aria-hidden="true">#</a></h2><p>性能优化很多时候不是一蹴而就的，更不是一锤子买卖。一个良好的性能优化方案一定是一个持续循环的体系。</p><p><img src="'+l+'" alt="circle"></p><p>一个合理的性能优化方案，一定是通过线上的性能监控数据，或者前端自动化性能测试分析，发现性能问题，针对发现的问题进行分析与定位，然后进行对应的性能优化，最后上线观察。之后又会进入到下一个性能优化的循环中。所以推行性能优化，一定要注重优化工程的可持续性。</p><h2 id="_3-监控与测试-💻" tabindex="-1">3. 监控与测试 💻 <a class="header-anchor" href="#_3-监控与测试-💻" aria-hidden="true">#</a></h2><p>性能监控与测试也是一块非常大的话题，包括监控的手段、分析的维度等等，如果后续有机会希望把这块再补充上来。这里先介绍一下。</p><p>我们一般会把<a href="https://developers.google.com/web/fundamentals/performance/speed-tools/" target="_blank" rel="noreferrer">性能数据分为两种</a><sup>[1]</sup>：</p><ul><li>一种叫 Lab data，主要是在开发和测试人员本地或内部测试机器上跑出来的数据，例如在 CI/CD 中加入 <a href="https://github.com/GoogleChrome/lighthouse" target="_blank" rel="noreferrer">lighthouse</a>。它的优点在于采集的指标更全面，也易于复现问题；缺点主要在于有时候可能不能反应真实的用户体验情况。</li><li>另一种叫 Field data，也被成为 RUM (Real User Monitoring)，是指采集线上实际的性能数据来进行监控。它的优点则是能更好地发现用户实际遇到的性能问题；缺点主要是比较难以调试与复现问题，同时采集到的指标的详细程度不及 Lab data。</li></ul><p>而 <a href="https://csswizardry.com/2018/10/three-types-of-performance-testing/" target="_blank" rel="noreferrer">The Three Types of Performance Testing</a><sup>[2]</sup> 则进一步划分出了三类性能测试。</p><ul><li>第一种叫做 Proactive：它可以理解为是工程师在开发阶段，通过浏览器调试等本地工具来发现并解决性能问题（善于利用 <a href="https://developers.google.com/web/tools/chrome-devtools/" target="_blank" rel="noreferrer">Chrome DevTools</a><sup>[3]</sup> 也是一个优秀前端工程师所需要具备的 😊）；</li><li>第二种叫做 Reactive：它是一种自动化的性能测试，可以集成到自动化测试或流水线的其他阶段，会在构建与每次发布前执行；</li><li>第三种叫做 Passive：它就是在产品发布后，通过收集线上数据（或用户反馈）来发现性能问题，主要是基于一些 RUM。</li></ul><p>选择哪种性能测试呢？答案是将它们结合使用（就像是自动化测试会结合单元测试、集成测试与端到端测试）。</p><p>对于一些易于标准化的性能标准，可以考虑使用 Proactive 和 Reactive 这样的 Lab data 来避免性能问题；而对于更复杂的业务场景，则可以通过 Passive 模式下的 Field data 进行监控。</p><h2 id="_4-自动化-🛠" tabindex="-1">4. 自动化 🛠 <a class="header-anchor" href="#_4-自动化-🛠" aria-hidden="true">#</a></h2><p>在性能优化上，请务必将可以自动化的工作都自动化。</p><p>前端性能优化的链路包括了「缓存 -&gt; 发送请求 -&gt; 等待响应 -&gt; 解析 -&gt; 处理各类静态资源 -&gt; 运行时 -&gt; 预加载（等待后续的请求）」，还是比较复杂的。因此，建议通过一些工具来将工作自动化。否则很可能无法保证性能优化的持续实施，因为它从来不是一锤子买卖。</p><p>在旅程中的各个技术点上，我也都会提到一些帮助快速实现优化或自动化的工具，例如 Workbox 提供的各类缓存方案、图片压缩的工具、webpack 插件等。还包括上面提到的，可以在 CI/CD 中集成的 <a href="https://github.com/GoogleChrome/lighthouse" target="_blank" rel="noreferrer">lighthouse</a><sup>[4]</sup> 这样的分析工具。而对于 RUM，如果你们公司有人力可以自建一套体系，如果自建成本较高，可以考虑接入一些免费或收费的商业公司产品。</p><hr><h2 id="参考资料" tabindex="-1">参考资料 <a class="header-anchor" href="#参考资料" aria-hidden="true">#</a></h2><ol><li><a href="https://developers.google.com/web/fundamentals/performance/speed-tools/" target="_blank" rel="noreferrer">How To Think About Speed Tools</a></li><li><a href="https://csswizardry.com/2018/10/three-types-of-performance-testing/" target="_blank" rel="noreferrer">The Three Types of Performance Testing</a></li><li><a href="https://developers.google.com/web/tools/chrome-devtools/evaluate-performance/" target="_blank" rel="noreferrer">Get Started With Analyzing Runtime Performance (Chrome DevTools)</a></li><li><a href="https://developers.google.com/web/tools/lighthouse/" target="_blank" rel="noreferrer">Lighthouse</a></li><li><a href="https://speedcurve.com/blog/user-timing-and-custom-metrics/" target="_blank" rel="noreferrer">User Timing and Custom Metrics</a></li><li><a href="https://developers.google.com/web/updates/2015/11/app-shell" target="_blank" rel="noreferrer">Instant Loading Web Apps with an Application Shell Architecture</a></li><li><a href="https://developers.google.com/web/fundamentals/performance/prpl-pattern/" target="_blank" rel="noreferrer">The PRPL Pattern</a></li><li><a href="https://tech.meituan.com/2018/11/15/first-contentful-paint-practice.html" target="_blank" rel="noreferrer">构建时预渲染：网页首帧优化实践</a></li><li><a href="https://developers.google.com/web/fundamentals/performance/rail#goals-and-guidelines" target="_blank" rel="noreferrer">Measure Performance with the RAIL Model</a></li></ol>',26),n=[i];function s(h,p,c,d,g,f){return t(),r("div",null,n)}const m=e(o,[["render",s]]);export{_ as __pageData,m as default};
